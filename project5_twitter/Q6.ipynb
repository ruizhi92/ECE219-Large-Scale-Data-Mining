{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime,time\n",
    "import pytz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statistics import mean\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files[0] => tweets_#gohawks.txt\n",
      "files[1] => tweets_#gopatriots.txt\n",
      "files[2] => tweets_#nfl.txt\n",
      "files[3] => tweets_#patriots.txt\n",
      "files[4] => tweets_#sb49.txt\n",
      "files[5] => tweets_#superbowl.txt\n"
     ]
    }
   ],
   "source": [
    "path = \"../../projects/project_5/ECE219_tweet_data/\"\n",
    "\n",
    "files = [\"tweets_#gohawks.txt\", \"tweets_#gopatriots.txt\", \\\n",
    "        \"tweets_#nfl.txt\", \"tweets_#patriots.txt\", \\\n",
    "        \"tweets_#sb49.txt\", \"tweets_#superbowl.txt\"]\n",
    "topics = [\"gohawks\", \"gopatriots\", \"nfl\", \"patriots\", \"sb49\", \"superbowl\"]\n",
    "\n",
    "for i, fl in enumerate(files):\n",
    "    print(\"files[\" + str(i) + \"] => \" + fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_time(data_raw,time_type):\n",
    "    \n",
    "    pst_tz = pytz.timezone('America/Los_Angeles')\n",
    "    \n",
    "    # sort according to time\n",
    "    pddata_raw = pd.DataFrame(data_raw,columns=['time','tweets','retweets','followers','mentioned',\\\n",
    "                                                'media','active','author','favourites_count','title'])\n",
    "    pddata_raw = pddata_raw.sort_values(by = 'time')\n",
    "    pddata_raw = pddata_raw.reset_index(drop=True)               \n",
    "\n",
    "    # calculate hour index and minute index from time\n",
    "    if time_type == 'hour':\n",
    "        hour_accu = []\n",
    "        for index, row in pddata_raw.iterrows():  \n",
    "            p = datetime.datetime.fromtimestamp(row['time'], pst_tz)  \n",
    "            hour_accu.append(((p.month-1)*31+p.day-14)*24+p.hour)                             \n",
    "        pddata_raw['time'] = hour_accu\n",
    "    elif time_type == 'minute':\n",
    "        minu_accu = []\n",
    "        for index, row in pddata_raw.iterrows():  \n",
    "            p = datetime.datetime.fromtimestamp(row['time'], pst_tz)                    \n",
    "            minu_accu.append((((p.month-1)*31+p.day-14)*24 + (p.hour-0))*12 + p.minute//5)             \n",
    "        pddata_raw['time'] = minu_accu    \n",
    "    else:\n",
    "        print(\"Invalid time type\")\n",
    "        \n",
    "    return pddata_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(pddata_raw):\n",
    "    \"\"\"\n",
    "    Create a new dataframe with desired form\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([],columns=['time unit','tweets','retweets','followers sum','followers max',\\\n",
    "                                  'mentioned','media','active','author','favourites_count','title'])\n",
    "    \n",
    "    col = pddata_raw.columns.get_loc('time')\n",
    "    df['time unit'] = range(int(pddata_raw.iloc[len(pddata_raw.index)-1,col] - pddata_raw.iloc[0,col]+1))\n",
    "\n",
    "    df['tweets'] = pddata_raw.groupby(\"time\")['tweets'].sum()\n",
    "    df['retweets'] = pddata_raw.groupby(\"time\")['retweets'].sum()\n",
    "    df['followers sum'] = pddata_raw.groupby(\"time\")['followers'].sum()\n",
    "    df['followers max'] = pddata_raw.groupby(\"time\")[\"followers\"].max()\n",
    "    df['mentioned'] = pddata_raw.groupby(\"time\")['mentioned'].sum()\n",
    "    df['media'] = pddata_raw.groupby(\"time\")['media'].sum()\n",
    "    df['active'] = pddata_raw.groupby(\"time\")['active'].mean()  \n",
    "    df['author'] = pddata_raw.groupby(\"time\")['author'].nunique() # count number of not-repeating authors    \n",
    "    df['favourites_count'] = pddata_raw.groupby(\"time\")['favourites_count'].sum()\n",
    "    df['title'] = pddata_raw.groupby(\"time\")['title'].mean()\n",
    "            \n",
    "    # reset index of df\n",
    "    df = df.fillna(0).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prase_dataset(file):\n",
    "    \"\"\"\n",
    "    Prase x conponent of the dataset into pandas DataFrame including columns of:\n",
    "    tweets, retweets, total_followers, max_followers, mentioned, media, active, author, favourites_count, title\n",
    "    with lines of hours,\n",
    "    where mentioned: number of @ in tweets per hour\n",
    "          media: number of url in tweets per hour\n",
    "          active: a measure of active state of author\n",
    "          author: number of unique authors post tweet per hour\n",
    "          favourites_count: the total number of likes by this user\n",
    "          title: length of this tweet's title\n",
    "    Prase y of dataset as number of tweets in the next hour.\n",
    "    \"\"\"\n",
    "    start_time = time.mktime(time.strptime(\"2015-02-01 08:00:00\",'%Y-%m-%d %H:%M:%S'))\n",
    "    end_time = time.mktime(time.strptime(\"2015-02-01 20:00:00\",'%Y-%m-%d %H:%M:%S'))   \n",
    "\n",
    "    start_hour_idx = ((2-1)*31+1-14)*24+8\n",
    "    end_hour_idx = ((2-1)*31+1-14)*24+20\n",
    "    start_minute_idx = (((2-1)*31+1-14)*24 + (8-0))*12 + 0//5    \n",
    "        \n",
    "    # extract raw features\n",
    "    data_raw = [[],[],[]]\n",
    "    for line in open(path + file, 'r') :\n",
    "        row_tmp = []\n",
    "        a = json.loads(line)\n",
    "        citation_date = a['citation_date']\n",
    "        tweet = 1\n",
    "        retweet = a['metrics']['citations']['total']\n",
    "        foll = a['author']['followers']             \n",
    "        ment = len(a['tweet']['entities']['user_mentions'])        \n",
    "        medi = len(a['tweet']['extended_entities']['media']) if 'extended_entities' in a['tweet'] else 0\n",
    "        hist_tw = a['tweet']['user'][\"statuses_count\"]\n",
    "        hist_yr = a['tweet']['user']['created_at'][-4:]\n",
    "        acti = hist_tw/(2015-float(hist_yr)+1) \n",
    "        auth = a['author']['name']\n",
    "        favo = a['tweet']['user']['favourites_count']\n",
    "        titl = len(a['title'])\n",
    "        \n",
    "        # append to row_tmp\n",
    "        row_tmp.append(citation_date)        \n",
    "        row_tmp.append(tweet)        \n",
    "        row_tmp.append(retweet)\n",
    "        row_tmp.append(foll)    \n",
    "        row_tmp.append(ment) \n",
    "        row_tmp.append(medi) \n",
    "        row_tmp.append(acti)  \n",
    "        row_tmp.append(auth)\n",
    "        row_tmp.append(favo)\n",
    "        row_tmp.append(titl)\n",
    "        \n",
    "        # assign to 3 periods\n",
    "        if citation_date < start_time:\n",
    "            data_raw[0].append(row_tmp)\n",
    "        elif citation_date < end_time:\n",
    "            data_raw[1].append(row_tmp)\n",
    "        else:\n",
    "            data_raw[2].append(row_tmp)            \n",
    "\n",
    "    # generate raw pandas dataframe\n",
    "    pddata_raw_1 = transfer_time(data_raw[0],'hour')\n",
    "    pddata_raw_2 = transfer_time(data_raw[1],'minute')\n",
    "    pddata_raw_2['time'] = pddata_raw_2['time'] - start_minute_idx\n",
    "    pddata_raw_3 = transfer_time(data_raw[2],'hour')\n",
    "    pddata_raw_3['time'] = pddata_raw_3['time'] - end_hour_idx - 1    \n",
    "            \n",
    "    # generate df and df_y for each time slot\n",
    "    df_1 = generate_df(pddata_raw_1)  \n",
    "    df_y_1 = df_1.iloc[1:,1].reset_index(drop=True)\n",
    "    df_1 = df_1[:len(df_y_1)]\n",
    "    \n",
    "    df_2 = generate_df(pddata_raw_2)\n",
    "    df_y_2 = df_2.iloc[1:,1].reset_index(drop=True)\n",
    "    df_2 = df_2[:len(df_y_2)]\n",
    "   \n",
    "    df_3 = generate_df(pddata_raw_3)\n",
    "    df_y_3 = df_3.iloc[1:,1].reset_index(drop=True)\n",
    "    df_3 = df_3[:len(df_y_3)]\n",
    "    \n",
    "    return (df_1.iloc[:,1:],df_y_1), (df_2.iloc[:,1:],df_y_2), (df_3.iloc[:,1:],df_y_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr(i):\n",
    "    \"\"\"\n",
    "    This function gets data and train using a linear regression model\n",
    "    \"\"\"    \n",
    "    (df_1,df_y_1),(df_2,df_y_2),(df_3,df_y_3) = prase_dataset(files[i])\n",
    "    print('Parse data finished','\\n')\n",
    "\n",
    "    reg_1 = LinearRegression().fit(df_1, df_y_1)\n",
    "    pred_y_1 = reg_1.predict(df_1)\n",
    "    MSE_1 = mean_squared_error(df_y_1, pred_y_1)\n",
    "    R2_1 = r2_score(df_y_1, pred_y_1)    \n",
    "    print(topics[i], ' of time period 1')\n",
    "    print('MSE for test data = ',MSE_1)\n",
    "    print('R2 score for test data = ',R2_1,'\\n')   \n",
    "\n",
    "    reg_2 = LinearRegression().fit(df_2, df_y_2)\n",
    "    pred_y_2 = reg_2.predict(df_2)\n",
    "    MSE_2 = mean_squared_error(df_y_2, pred_y_2)\n",
    "    R2_2 = r2_score(df_y_2, pred_y_2)    \n",
    "    print(topics[i], ' of time period 2')\n",
    "    print('MSE for test data = ',MSE_2)\n",
    "    print('R2 score for test data = ',R2_2,'\\n') \n",
    "\n",
    "    reg_3 = LinearRegression().fit(df_3, df_y_3)\n",
    "    pred_y_3 = reg_3.predict(df_3)\n",
    "    MSE_3 = mean_squared_error(df_y_3, pred_y_3)\n",
    "    R2_3 = r2_score(df_y_3, pred_y_3)    \n",
    "    print(topics[i], ' of time period 3')\n",
    "    print('MSE for test data = ',MSE_3)\n",
    "    print('R2 score for test data = ',R2_3,'\\n') \n",
    "    \n",
    "    return (df_1, df_y_1, pred_y_1), (df_2, df_y_2, pred_y_2), (df_3, df_y_3, pred_y_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gohawks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse data finished \n",
      "\n",
      "gohawks  of time period 1\n",
      "MSE for test data =  414263.04817109066\n",
      "R2 score for test data =  0.598161945585284 \n",
      "\n",
      "gohawks  of time period 2\n",
      "MSE for test data =  63160.147810741204\n",
      "R2 score for test data =  0.5547907515717387 \n",
      "\n",
      "gohawks  of time period 3\n",
      "MSE for test data =  919.8478574822856\n",
      "R2 score for test data =  0.8959158441687535 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_1, df_y_1, pred_y_1), (df_2, df_y_2, pred_y_2), (df_3, df_y_3, pred_y_3) = train_lr(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gopatriots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse data finished \n",
      "\n",
      "gopatriots  of time period 1\n",
      "MSE for test data =  1196.4484741182887\n",
      "R2 score for test data =  0.7080866576767786 \n",
      "\n",
      "gopatriots  of time period 2\n",
      "MSE for test data =  13902.440230090087\n",
      "R2 score for test data =  0.45870700231074846 \n",
      "\n",
      "gopatriots  of time period 3\n",
      "MSE for test data =  2.734346947494579\n",
      "R2 score for test data =  0.981672264517095 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_1, df_y_1, pred_y_1), (df_2, df_y_2, pred_y_2), (df_3, df_y_3, pred_y_3) = train_lr(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse data finished \n",
      "\n",
      "nfl  of time period 1\n",
      "MSE for test data =  59097.839883621986\n",
      "R2 score for test data =  0.5622301246225405 \n",
      "\n",
      "nfl  of time period 2\n",
      "MSE for test data =  15448.2604714677\n",
      "R2 score for test data =  0.8662712504630752 \n",
      "\n",
      "nfl  of time period 3\n",
      "MSE for test data =  15726.387836028154\n",
      "R2 score for test data =  0.8193018818392885 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_1, df_y_1, pred_y_1), (df_2, df_y_2, pred_y_2), (df_3, df_y_3, pred_y_3) = train_lr(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### patriots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse data finished \n",
      "\n",
      "patriots  of time period 1\n",
      "MSE for test data =  292559.76189079345\n",
      "R2 score for test data =  0.6255415231220794 \n",
      "\n",
      "patriots  of time period 2\n",
      "MSE for test data =  592589.0646312773\n",
      "R2 score for test data =  0.7443493708746511 \n",
      "\n",
      "patriots  of time period 3\n",
      "MSE for test data =  5485.772795474432\n",
      "R2 score for test data =  0.9307790836817433 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_1, df_y_1, pred_y_1), (df_2, df_y_2, pred_y_2), (df_3, df_y_3, pred_y_3) = train_lr(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sb49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse data finished \n",
      "\n",
      "sb49  of time period 1\n",
      "MSE for test data =  3967.9293381128236\n",
      "R2 score for test data =  0.8726677185837142 \n",
      "\n",
      "sb49  of time period 2\n",
      "MSE for test data =  1061154.1755915731\n",
      "R2 score for test data =  0.889568015315917 \n",
      "\n",
      "sb49  of time period 3\n",
      "MSE for test data =  16093.080413140482\n",
      "R2 score for test data =  0.951778592832415 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_1, df_y_1, pred_y_1), (df_2, df_y_2, pred_y_2), (df_3, df_y_3, pred_y_3) = train_lr(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### superbowl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse data finished \n",
      "\n",
      "superbowl  of time period 1\n",
      "MSE for test data =  460135.94631149515\n",
      "R2 score for test data =  0.4667714326573307 \n",
      "\n",
      "superbowl  of time period 2\n",
      "MSE for test data =  4188144.4709006567\n",
      "R2 score for test data =  0.9329302244854544 \n",
      "\n",
      "superbowl  of time period 3\n",
      "MSE for test data =  86282.69151023673\n",
      "R2 score for test data =  0.8777853512797381 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_1, df_y_1, pred_y_1), (df_2, df_y_2, pred_y_2), (df_3, df_y_3, pred_y_3) = train_lr(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
