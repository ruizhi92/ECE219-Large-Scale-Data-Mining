{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime,time\n",
    "import pytz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statistics import mean\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files[0] => tweets_#gohawks.txt\n",
      "files[1] => tweets_#gopatriots.txt\n",
      "files[2] => tweets_#nfl.txt\n",
      "files[3] => tweets_#patriots.txt\n",
      "files[4] => tweets_#sb49.txt\n",
      "files[5] => tweets_#superbowl.txt\n"
     ]
    }
   ],
   "source": [
    "path = \"tweet_data/\"\n",
    "\n",
    "files = [\"tweets_#gohawks.txt\", \"tweets_#gopatriots.txt\", \\\n",
    "        \"tweets_#nfl.txt\", \"tweets_#patriots.txt\", \\\n",
    "        \"tweets_#sb49.txt\", \"tweets_#superbowl.txt\"]\n",
    "topics = [\"gohawks\", \"gopatriots\", \"nfl\", \"patriots\", \"sb49\", \"superbowl\"]\n",
    "\n",
    "for i, fl in enumerate(files):\n",
    "    print(\"files[\" + str(i) + \"] => \" + fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(pddata_raw):\n",
    "    \"\"\"\n",
    "    Create a new dataframe with desired form\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([],columns=['time unit','tweets','retweets','followers sum','followers max','hr_min'])\n",
    "    \n",
    "    col = pddata_raw.columns.get_loc('time')\n",
    "    df['time unit'] = range(int(pddata_raw.iloc[len(pddata_raw.index)-1,col] - pddata_raw.iloc[0,col]+1))\n",
    "    df['tweets'] = pddata_raw.groupby(\"time\")['tweets'].sum()\n",
    "    df['retweets'] = pddata_raw.groupby(\"time\")['retweets'].sum()\n",
    "    df['followers sum'] = pddata_raw.groupby(\"time\")['followers'].sum()\n",
    "    df['followers max'] = pddata_raw.groupby(\"time\")[\"followers\"].max()\n",
    "    df['hr_min'] = pddata_raw.groupby(\"time\")['hr_min'].mean()        \n",
    "    # reset index of df\n",
    "    df = df.fillna(0).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_dataset(path,files):\n",
    "    \"\"\"\n",
    "    Parse x conponent of the dataset into pandas DataFrame including columns of:\n",
    "    tweets, retweets, total_followers, max_followers, mentioned, media, active, author, favourites_count, title\n",
    "    with lines of hours,\n",
    "    where mentioned: number of @ in tweets per hour\n",
    "          media: number of url in tweets per hour\n",
    "          active: a measure of active state of author\n",
    "          author: number of unique authors post tweet per hour\n",
    "          favourites_count: the total number of likes by this user\n",
    "          title: length of this tweet's title\n",
    "    Parse y of dataset as number of tweets in the next hour.\n",
    "    \"\"\"\n",
    "    start_time = time.mktime(time.strptime(\"2015-02-01 08:00:00\",'%Y-%m-%d %H:%M:%S'))\n",
    "    end_time = time.mktime(time.strptime(\"2015-02-01 20:00:00\",'%Y-%m-%d %H:%M:%S'))   \n",
    "\n",
    "    start_hour_idx = ((2-1)*31+1-14)*24+8\n",
    "    end_hour_idx = ((2-1)*31+1-14)*24+20\n",
    "    start_minute_idx = (((2-1)*31+1-14)*24 + (8-0))*12 + 0//5    \n",
    "        \n",
    "    # extract raw features\n",
    "    data_raw = [[],[],[]]\n",
    "    for file in files:\n",
    "        for line in open(path + file, 'r', encoding=\"utf-8\") :\n",
    "            row_tmp = []\n",
    "            a = json.loads(line)\n",
    "            citation_date = a['citation_date']\n",
    "            tweet = 1\n",
    "            retweet = a['metrics']['citations']['total']\n",
    "            foll = a['author']['followers']\n",
    "            hr_min=1\n",
    "\n",
    "            # append to row_tmp\n",
    "            row_tmp.append(citation_date)        \n",
    "            row_tmp.append(tweet)        \n",
    "            row_tmp.append(retweet)\n",
    "            row_tmp.append(foll)  \n",
    "            row_tmp.append(hr_min) \n",
    "            # assign to 3 periods\n",
    "            if citation_date < start_time:\n",
    "                data_raw[0].append(row_tmp)\n",
    "            elif citation_date < end_time:\n",
    "                data_raw[1].append(row_tmp)\n",
    "            else:\n",
    "                data_raw[2].append(row_tmp)            \n",
    "\n",
    "    # generate raw pandas dataframe\n",
    "    pddata_raw_1 = transfer_time(data_raw[0],'hour')\n",
    "    pddata_raw_1['time'] = pddata_raw_1['time'] - pddata_raw_1.loc[0,'time']\n",
    "    \n",
    "    pddata_raw_2 = transfer_time(data_raw[1],'minute')\n",
    "#     pddata_raw_2['time'] = pddata_raw_2['time'] - start_minute_idx\n",
    "    pddata_raw_2['time'] = pddata_raw_2['time'] - pddata_raw_2.loc[0,'time']\n",
    "\n",
    "    pddata_raw_3 = transfer_time(data_raw[2],'hour')\n",
    "#     pddata_raw_3['time'] = pddata_raw_3['time'] - end_hour_idx - 1    \n",
    "    pddata_raw_3['time'] = pddata_raw_3['time'] - pddata_raw_3.loc[0,'time']\n",
    "    #print('1',pddata_raw_1)\n",
    "    \n",
    "    # generate df and df_y for each time slot\n",
    "    df_1 = generate_df(pddata_raw_1)  \n",
    "    df_y_1 = df_1.iloc[1:,1].reset_index(drop=True)\n",
    "    df_1 = df_1[:len(df_y_1)]\n",
    "    #print('2',df_1)\n",
    "    \n",
    "    df_2 = generate_df(pddata_raw_2)\n",
    "    df_y_2 = df_2.iloc[1:,1].reset_index(drop=True)\n",
    "    df_2 = df_2[:len(df_y_2)]\n",
    "   \n",
    "    df_3 = generate_df(pddata_raw_3)\n",
    "    df_y_3 = df_3.iloc[1:,1].reset_index(drop=True)\n",
    "    df_3 = df_3[:len(df_y_3)]\n",
    "    \n",
    "    return (df_1.iloc[:,1:],df_y_1), (df_2.iloc[:,1:],df_y_2), (df_3.iloc[:,1:],df_y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_time(data_raw,time_type):\n",
    "    \n",
    "    pst_tz = pytz.timezone('America/Los_Angeles')\n",
    "    \n",
    "    # sort according to time\n",
    "    pddata_raw = pd.DataFrame(data_raw,columns=['time','tweets','retweets','followers','hr_min'])\n",
    "    pddata_raw = pddata_raw.sort_values(by = 'time')\n",
    "    pddata_raw = pddata_raw.reset_index(drop=True)               \n",
    "\n",
    "    # calculate hour index and minute index from time\n",
    "    if time_type == 'hour':\n",
    "        hour_accu = []\n",
    "        hour_min = []\n",
    "        for index, row in pddata_raw.iterrows():  \n",
    "            p = datetime.datetime.fromtimestamp(row['time'], pst_tz)  \n",
    "            hour_accu.append(((p.month-1)*31+p.day-14)*24+p.hour)  \n",
    "            hour_min.append(p.hour)\n",
    "        pddata_raw['time'] = hour_accu\n",
    "        pddata_raw['hr_min'] = hour_min\n",
    "    elif time_type == 'minute':\n",
    "        minu_accu = []\n",
    "        hour_min = []\n",
    "        for index, row in pddata_raw.iterrows():  \n",
    "            p = datetime.datetime.fromtimestamp(row['time'], pst_tz)                    \n",
    "            minu_accu.append((((p.month-1)*31+p.day-14)*24 + (p.hour-0))*12 + p.minute//5)   \n",
    "            hour_min.append(p.minute//5)\n",
    "        pddata_raw['time'] = minu_accu    \n",
    "        pddata_raw['hr_min'] = hour_min\n",
    "    else:\n",
    "        print(\"Invalid time type\")\n",
    "        \n",
    "    return pddata_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def six_times_window(df,df_y):\n",
    "    m=df.shape[0]\n",
    "    df_new= pd.DataFrame(np.zeros((m-4,5)),columns=['tweets','retweets','followers sum','followers max',\\\n",
    "                                  'hr_min'])\n",
    "    df_y_new= pd.DataFrame(np.zeros((m-4)))\n",
    "    for i in range(m-4):\n",
    "        \n",
    "        for j in range(5):\n",
    "            df_new.iloc[i,j]=(df.iloc[i,j]+df.iloc[i+1,j]+df.iloc[i+2,j]+df.iloc[i+3,j]+df.iloc[i+4,j])\n",
    "        j=3\n",
    "        df_new.iloc[i,3]=np.max([df.iloc[i,j],df.iloc[i+1,j],df.iloc[i+2,j],df.iloc[i+3,j],df.iloc[i+4,j]])\n",
    "        df_y_new.iloc[i,0]=df_y.iloc[i+4]\n",
    "    \n",
    "    return df_new, df_y_new    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_recipe(df_y, pred_y):\n",
    "    \"\"\"\n",
    "    This function plots fitted values vs true values\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    area = np.pi * (4)**2/4\n",
    "    plt.scatter(df_y, pred_y, s = area)\n",
    "    plt.plot([df_y.min(), df_y.max()], [df_y.min(), df_y.max()], 'k--', lw = 1)\n",
    "    plt.xlabel('true values')\n",
    "    plt.ylabel('fitted values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dfo,dfo_y),(dfo_2,dfo_y_2),(dfo_3,dfo_y_3) =parse_dataset(path,files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_y  =six_times_window(dfo,dfo_y)\n",
    "df_2, df_y_2  =six_times_window(dfo_2,dfo_y_2)\n",
    "df_3, df_y_3  =six_times_window(dfo_3,dfo_y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files_1 =[\"sample0_period1.txt\",\"sample0_period2.txt\",\"sample0_period3.txt\"]\n",
    "test_files_2 =[\"sample1_period1.txt\",\"sample1_period2.txt\",\"sample1_period3.txt\"]\n",
    "test_files_3 =[\"sample2_period1.txt\",\"sample2_period2.txt\",\"sample2_period3.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_test1,df_y_test1),(df_2_test1,df_y_2_test1),(df_3_test1,df_y_3_test1) = parse_dataset(path,test_files_1)\n",
    "(df_test2,df_y_test2),(df_2_test2,df_y_2_test2),(df_3_test2,df_y_3_test2) = parse_dataset(path,test_files_2)\n",
    "(df_test3,df_y_test3),(df_2_test3,df_y_2_test3),(df_3_test3,df_y_3_test3) = parse_dataset(path,test_files_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>retweets</th>\n",
       "      <th>followers sum</th>\n",
       "      <th>followers max</th>\n",
       "      <th>hr_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>109</td>\n",
       "      <td>424498.0</td>\n",
       "      <td>168371.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>761</td>\n",
       "      <td>2975692.0</td>\n",
       "      <td>2034387.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>226</td>\n",
       "      <td>860594.0</td>\n",
       "      <td>328882.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>258</td>\n",
       "      <td>2349147.0</td>\n",
       "      <td>368626.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122</td>\n",
       "      <td>483</td>\n",
       "      <td>1369748.0</td>\n",
       "      <td>291130.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweets  retweets  followers sum  followers max  hr_min\n",
       "0      52       109       424498.0       168371.0       5\n",
       "1      79       761      2975692.0      2034387.0       6\n",
       "2      94       226       860594.0       328882.0       7\n",
       "3     101       258      2349147.0       368626.0       8\n",
       "4     122       483      1369748.0       291130.0       9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1, df_y_test1  =six_times_window(df_test1,df_y_test1)\n",
    "df_2_test1, df_y_2_test1  =six_times_window(df_2_test1,df_y_2_test1)\n",
    "df_3_test1, df_y_3_test1  =six_times_window(df_3_test1,df_y_3_test1)\n",
    "df_test2, df_y_test2  =six_times_window(df_test2,df_y_test2)\n",
    "df_2_test2, df_y_2_test2  =six_times_window(df_2_test2,df_y_2_test2)\n",
    "df_3_test2, df_y_3_test2  =six_times_window(df_3_test2,df_y_3_test2)\n",
    "df_test3, df_y_test3  =six_times_window(df_test3,df_y_test3)\n",
    "df_2_test3, df_y_2_test3  =six_times_window(df_2_test3,df_y_2_test3)\n",
    "df_3_test3, df_y_3_test3  =six_times_window(df_3_test3,df_y_3_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "0  120.0        0\n",
      "0  846.0       0\n",
      "0  61.0\n",
      "[340.77519001] [638.33634891] [202.79927484]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor(oob_score=True,n_estimators=200,max_depth=20,min_samples_leaf=2,min_samples_split=10, bootstrap=True,max_features='sqrt',random_state=42)\n",
    "reg.fit(df,df_y)\n",
    "pred = reg.predict(df)\n",
    "pred1=reg.predict(df_test1)\n",
    "pred2=reg.predict(df_test2)\n",
    "pred3=reg.predict(df_test3)\n",
    "print(df_y_test1,df_y_test2,df_y_test3)\n",
    "print(pred1,pred2,pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "0  1123.0        0\n",
      "0  903.0       0\n",
      "0  28.0\n",
      "[5062.22864342] [1085.21591104] [1042.27265207]\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor(oob_score=True,n_estimators=1200,max_depth=20,min_samples_leaf=4,min_samples_split=2, bootstrap=True,max_features='sqrt',random_state=42)\n",
    "reg.fit(df_2,df_y_2)\n",
    "pred = reg.predict(df_2)\n",
    "pred1=reg.predict(df_2_test1)\n",
    "pred2=reg.predict(df_2_test2)\n",
    "pred3=reg.predict(df_2_test3)\n",
    "print(df_y_2_test1,df_y_2_test2,df_y_2_test3)\n",
    "print(pred1,pred2,pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0  87.0       0\n",
      "0  46.0       0\n",
      "0  43.0\n",
      "[103.95607076] [199.11456449] [203.31185616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor(oob_score=True,n_estimators=200,max_depth=20,min_samples_leaf=4,min_samples_split=2, bootstrap=True,max_features='sqrt',random_state=42)\n",
    "reg.fit(df_3,df_y_3)\n",
    "pred = reg.predict(df_3)\n",
    "pred1=reg.predict(df_3_test1)\n",
    "pred2=reg.predict(df_3_test2)\n",
    "pred3=reg.predict(df_3_test3)\n",
    "print(df_y_3_test1,df_y_3_test2,df_y_3_test3)\n",
    "print(pred1,pred2,pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "0  120.0        0\n",
      "0  846.0       0\n",
      "0  61.0\n",
      "[298.04358475] [573.50261936] [177.73571437]\n"
     ]
    }
   ],
   "source": [
    "reg = GradientBoostingRegressor(n_estimators=200,max_depth=20,min_samples_leaf=2,min_samples_split=10, max_features='sqrt',random_state=42)\n",
    "reg.fit(df,df_y)\n",
    "pred = reg.predict(df)\n",
    "pred1=reg.predict(df_test1)\n",
    "pred2=reg.predict(df_test2)\n",
    "pred3=reg.predict(df_test3)\n",
    "print(df_y_test1,df_y_test2,df_y_test3)\n",
    "print(pred1,pred2,pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "0  1123.0        0\n",
      "0  903.0       0\n",
      "0  28.0\n",
      "[6816.75807019] [1016.80809268] [965.41975729]\n"
     ]
    }
   ],
   "source": [
    "reg = GradientBoostingRegressor(n_estimators=1200,max_depth=20,min_samples_leaf=4,min_samples_split=2, max_features='sqrt',random_state=42)\n",
    "reg.fit(df_2,df_y_2)\n",
    "pred = reg.predict(df_2)\n",
    "pred1=reg.predict(df_2_test1)\n",
    "pred2=reg.predict(df_2_test2)\n",
    "pred3=reg.predict(df_2_test3)\n",
    "print(df_y_2_test1,df_y_2_test2,df_y_2_test3)\n",
    "print(pred1,pred2,pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0  87.0       0\n",
      "0  46.0       0\n",
      "0  43.0\n",
      "[30.03838049] [11.88626886] [30.80890984]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "reg = GradientBoostingRegressor(n_estimators=200,max_depth=20,min_samples_leaf=4,min_samples_split=2, max_features='sqrt',random_state=42)\n",
    "reg.fit(df_3,df_y_3)\n",
    "pred = reg.predict(df_3)\n",
    "pred1=reg.predict(df_3_test1)\n",
    "pred2=reg.predict(df_3_test2)\n",
    "pred3=reg.predict(df_3_test3)\n",
    "print(df_y_3_test1,df_y_3_test2,df_y_3_test3)\n",
    "print(pred1,pred2,pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 3988798.5055075316\n",
      "       0\n",
      "0  120.0        0\n",
      "0  846.0       0\n",
      "0  61.0\n",
      "[138.64449719] [597.74290231] [294.78384788]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "df_trans=scaler.transform(df)\n",
    "reg = MLPRegressor(hidden_layer_sizes=(50,600,300,),activation='relu', solver='adam', alpha=1e-5, random_state=42) \n",
    "reg.fit(df_trans,df_y)\n",
    "pred = reg.predict(df_trans)\n",
    "print(\"MSE=\",mean_squared_error(df_y, pred))\n",
    "pred1=reg.predict(scaler.transform(df_test1))\n",
    "pred2=reg.predict(scaler.transform(df_test2))\n",
    "pred3=reg.predict(scaler.transform(df_test3))\n",
    "print(df_y_test1,df_y_test2,df_y_test3)\n",
    "print(pred1,pred2,pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 33264948.38992299\n",
      "        0\n",
      "0  1123.0        0\n",
      "0  903.0       0\n",
      "0  28.0\n",
      "[6774.20236825] [6051.60427666] [6946.44812688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df_2)\n",
    "df_2_trans=scaler.transform(df_2)\n",
    "reg = MLPRegressor(hidden_layer_sizes=(600,600,600,),activation='relu', solver='adam', alpha=1e-5, random_state=42) \n",
    "reg.fit(df_2_trans,df_y_2)\n",
    "pred = reg.predict(df_2_trans)\n",
    "print(\"MSE=\",mean_squared_error(df_y_2, pred))\n",
    "pred1=reg.predict(scaler.transform(df_2_test1))\n",
    "pred2=reg.predict(scaler.transform(df_2_test2))\n",
    "pred3=reg.predict(scaler.transform(df_2_test3))\n",
    "print(df_y_2_test1,df_y_2_test2,df_y_2_test3)\n",
    "print(pred1,pred2,pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 183911.8928080028\n",
      "      0\n",
      "0  87.0       0\n",
      "0  46.0       0\n",
      "0  43.0\n",
      "[574.67856497] [362.31850104] [402.85187849]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df_3)\n",
    "df_3_trans=scaler.transform(df_3)\n",
    "reg = MLPRegressor(hidden_layer_sizes=(600,600,600,),activation='relu', solver='adam', alpha=1e-5, random_state=42) \n",
    "reg.fit(df_3_trans,df_y_3)\n",
    "pred = reg.predict(df_3_trans)\n",
    "print(\"MSE=\",mean_squared_error(df_y_3, pred))\n",
    "pred1=reg.predict(scaler.transform(df_3_test1))\n",
    "pred2=reg.predict(scaler.transform(df_3_test2))\n",
    "pred3=reg.predict(scaler.transform(df_3_test3))\n",
    "print(df_y_3_test1,df_y_3_test2,df_y_3_test3)\n",
    "print(pred1,pred2,pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
